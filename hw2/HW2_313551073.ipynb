{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "logdir = f'./records'\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "writer = SummaryWriter(logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(filename):\n",
    "    \"\"\"Load training data and return as a NumPy array, excluding headers and category column.\"\"\"\n",
    "    data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()[1:]  # Skip header\n",
    "        for line in lines:\n",
    "            parts = line.strip().split(',')[1:]  # Ignore the first column (category)\n",
    "            data.append([int(x) for x in parts])\n",
    "    return np.array(data, dtype=np.float32)\n",
    "\n",
    "def load_test_data(filename):\n",
    "    \"\"\"Load test data and return as a NumPy array, excluding the header.\"\"\"\n",
    "    data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()[1:]  # Skip header\n",
    "        for line in lines:\n",
    "            parts = line.strip().split(',')\n",
    "            data.append([int(x) for x in parts])\n",
    "    return np.array(data, dtype=np.float32)\n",
    "\n",
    "def save_anomaly_scores(test_data, scores, output_file):\n",
    "    \"\"\"Save anomaly scores to a CSV file.\"\"\"\n",
    "    with open(output_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\", \"outliers\"])\n",
    "        for idx, score in enumerate(scores):\n",
    "            writer.writerow([idx, score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=16):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, latent_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, input_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "def train_autoencoder(data, epochs=1000, lr=0.001):\n",
    "    \"\"\"Train an autoencoder with MSE loss.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    input_dim = data.shape[1]\n",
    "    model = Autoencoder(input_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    train_data = torch.tensor(data, dtype=torch.float32).to(device)\n",
    "    pbar = tqdm(range(epochs), desc=f\"Training Progress: \")\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_data)\n",
    "        loss = criterion(output, train_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar('AutoEncoder Loss', loss.item(), epoch+1)\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    torch.save(model.state_dict(), \"autoencoder_model.pth\")\n",
    "    print(\"Model saved to autoencoder_model.pth\")\n",
    "    return model\n",
    "\n",
    "def anomaly_score(model, test_samples):\n",
    "    \"\"\"Compute the MSE anomaly scores for given test samples.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    test_samples = torch.tensor(test_samples, dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        reconstructed = model(test_samples)\n",
    "    mse = ((reconstructed - test_samples) ** 2).mean(dim=1).cpu().numpy()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn(data, n_neighbors=5, contamination=0.1):\n",
    "    \"\"\"Train a k-Nearest Neighbors (kNN) model for anomaly detection using Local Outlier Factor.\"\"\"\n",
    "    model = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, novelty=True)\n",
    "    model.fit(data)\n",
    "    return model\n",
    "\n",
    "def anomaly_score(model, test_samples):\n",
    "    \"\"\"Compute anomaly scores for test samples using kNN-based Local Outlier Factor.\"\"\"\n",
    "    scores = -model.decision_function(test_samples)  # Negate to align with anomaly scoring convention\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneClass SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_oneclass_svm(data, nu=0.01, kernel='rbf', gamma='scale'):\n",
    "    \"\"\"Train a One-Class SVM for anomaly detection.\"\"\"\n",
    "    model = OneClassSVM(nu=nu, kernel=kernel, gamma=gamma)\n",
    "    model.fit(data)\n",
    "    return model\n",
    "\n",
    "def anomaly_score(model, test_samples):\n",
    "    \"\"\"Compute anomaly scores for test samples using One-Class SVM.\"\"\"\n",
    "    scores = -model.decision_function(test_samples)  # Negate to align with MSE convention\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = load_training_data(\"training.csv\")  # (4200, 16)\n",
    "test_data = load_test_data(\"test_X.csv\")    # (1000, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_model = train_autoencoder(training_data, epochs=5000)\n",
    "scores = anomaly_score(ae_model, test_data)\n",
    "save_anomaly_scores(test_data, scores, \"ae_anomaly_scores.csv\")\n",
    "print(\"Anomaly scores saved to ae_anomaly_scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = train_knn(training_data)\n",
    "scores = anomaly_score(knn_model, test_data)\n",
    "save_anomaly_scores(test_data, scores, \"knn_anomaly_scores.csv\")\n",
    "print(\"Anomaly scores saved to knn_anomaly_scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneClass SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = train_oneclass_svm(training_data)\n",
    "scores = anomaly_score(svm_model, test_data)\n",
    "save_anomaly_scores(test_data, scores, \"svm_anomaly_scores.csv\")\n",
    "print(\"Anomaly scores saved to svm_anomaly_scores.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
